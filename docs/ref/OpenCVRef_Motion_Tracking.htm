<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0//EN">
<html><head>
<link rel="STYLESHEET" href="opencvref.css" charset="ISO-8859-1" type="text/css">
<title>Motion Analysis and Object Tracking Reference</title>
</head><body>

<h1>Motion Analysis and Object Tracking Reference</h1>

<hr><p><ul>
<li><a href="#ch4_acc">Accumulation of Background Statistics</a>
<ul>
<li><a href="#decl_cvAcc">Acc</a>
<li><a href="#decl_cvSquareAcc">SquareAcc</a>
<li><a href="#decl_cvMultiplyAcc">MultiplyAcc</a>
<li><a href="#decl_cvRunningAvg">RunningAvg</a>
</ul>
<li><a href="#ch4_motempl">Motion Templates</a>
<ul>
<li><a href="#decl_cvUpdateMotionHistory">UpdateMotionHistory</a>
<li><a href="#decl_cvCalcMotionGradient">CalcMotionGradient</a>
<li><a href="#decl_cvCalcGlobalOrientation">CalcGlobalOrientation</a>
<li><a href="#decl_cvSegmentMotion">SegmentMotion</a>
</ul>
<li><a href="#ch4_tracking">Object Tracking</a>
<ul>
<li><a href="#decl_cvMeanShift">MeanShift</a>
<li><a href="#decl_cvCamShift">CamShift</a>
<li><a href="#decl_cvSnakeImage">SnakeImage</a>
</ul>
<li><a href="#ch4_optflow">Optical Flow</a>
<ul>
<li><a href="#decl_cvCalcOpticalFlowHS">CalcOpticalFlowHS</a>
<li><a href="#decl_cvCalcOpticalFlowLK">CalcOpticalFlowLK</a>
<li><a href="#decl_cvCalcOpticalFlowBM">CalcOpticalFlowBM</a>
<li><a href="#decl_cvCalcOpticalFlowPyrLK">CalcOpticalFlowPyrLK</a>
</ul>
<li><a href="#ch4_estimators">Estimators</a>
<ul>
<li><a href="#decl_CvKalman">Kalman</a>
<li><a href="#decl_cvCreateKalman">CreateKalman</a>
<li><a href="#decl_cvReleaseKalman">ReleaseKalman</a>
<li><a href="#decl_cvKalmanPredict">KalmanPredict</a>
<li><a href="#decl_cvKalmanCorrect">KalmanCorrect</a>
<li><a href="#decl_cvCreateConDensation">CreateConDensation</a>
<li><a href="#decl_cvReleaseConDensation">ReleaseConDensation</a>
<li><a href="#decl_cvConDensInitSampleSet">ConDensInitSampleSet</a>
<li><a href="#decl_cvConDensUpdateByTime">ConDensUpdateByTime</a>
</ul></ul></p>


<hr><h2><a name="ch4_acc">Accumulation of Background Statistics</a></h2>

<hr><h3><a name="decl_cvAcc">Acc</a></h3>
<p class="Blurb">Adds frame to accumulator</p>
<pre>
void cvAcc( const CvArr* I, CvArr* S, const CvArr* mask=0 );
</pre><p><dl>
<dt>I<dd>Input image, 1- or 3-channel, 8-bit or 32-bit floating point.
         (each channel of multi-channel image is processed independently).
<dt>S<dd>Accumulator of the same number of channels as input image, 32-bit or 64-bit floating-point.
<dt>mask<dd>Optional operation mask.
</dl></p><p>
The function <a href="#decl_cvAcc">cvAcc</a> adds the whole image <em>I</em> or its selected region to accumulator <em>S</em>:</p>
<pre>
S(x,y)=S(x,y)+I(x,y) if mask(x,y)!=0
</pre>


<hr><h3><a name="decl_cvSquareAcc">SquareAcc</a></h3>
<p class="Blurb">Adds the square of source image to accumulator</p>
<pre>
void cvSquareAcc( const CvArr* img, CvArr* sqSum, const CvArr* mask=0 );
</pre><p><dl>
<dt>I<dd>Input image, 1- or 3-channel, 8-bit or 32-bit floating point
         (each channel of multi-channel image is processed independently).
<dt>Sq<dd>Accumulator of the same number of channels as input image, 32-bit or 64-bit floating-point.
<dt>mask<dd>Optional operation mask.
</dl></p><p>
The function <a href="#decl_cvSquareAcc">cvSquareAcc</a> adds the square of input image <em>I</em> or its selected region to
accumulator <em>Sq</em>:</p>
<pre>
Sq(x,y)=Sq(x,y)+I(x,y)<sup>2</sup> if mask(x,y)!=0
</pre>


<hr><h3><a name="decl_cvMultiplyAcc">MultiplyAcc</a></h3>
<p class="Blurb">Adds product of two input images to accumulator</p>
<pre>
void cvMultiplyAcc( const CvArr* I, const CvArr* J, CvArr* Sp, const CvArr* mask=0 );
</pre><p><dl>
<dt>I<dd>First input image, 1- or 3-channel, 8-bit or 32-bit floating point
         (each channel of multi-channel image is processed independently).
<dt>J<dd>Second input image, the same format as <em>I</em>.
<dt>Sp<dd>Accumulator of the same number of channels as input images, 32-bit or 64-bit floating-point.
<dt>mask<dd>Optional operation mask.
</dl></p><p>
The function <a href="#decl_cvMultiplyAcc">cvMultiplyAcc</a> adds product of the whole images <em>I</em> and <em>J</em>
or their selected regions to accumulator <em>Sp</em>:</p>
<pre>
Sp(x,y)=Sp(x,y)+I(x,y)&bull;J(x,y) if mask(x,y)!=0
</pre>


<hr><h3><a name="decl_cvRunningAvg">RunningAvg</a></h3>
<p class="Blurb">Updates running average</p>
<pre>
void cvRunningAvg( const CvArr* I, CvArr* R, double alpha, const CvArr* mask=0 );
</pre><p><dl>
<dt>I<dd>Input image, 1- or 3-channel, 8-bit or 32-bit floating point
         (each channel of multi-channel image is processed independently).
<dt>R<dd>Accumulator of the same number of channels as input image, 32-bit or 64-bit floating-point.
<dt>alpha<dd>Weight of input image.
<dt>mask<dd>Optional operation mask.
</dl></p><p>
The function <a href="#decl_cvRunningAvg">cvRunningAvg</a> calculates weighted sum of input image <em>I</em> and
accumulator <em>R</em> so that <em>R</em> becomes a running average of frame sequence:</p>
<pre>
R(x,y)=(1-&alpha;)&bull;R(x,y) + &alpha;&bull;I(x,y) if mask(x,y)!=0
</pre><p>
where &alpha; (alpha) regulates update speed (how fast accumulator forgets about previous frames).
</p>


<hr><h2><a name="ch4_motempl">Motion Templates</a></h2>

<hr><h3><a name="decl_cvUpdateMotionHistory">UpdateMotionHistory</a></h3>
<p class="Blurb">Updates motion history image by moving silhouette</p>
<pre>
void cvUpdateMotionHistory( const CvArr* S, CvArr* MHI,
                            double timestamp, double duration );
</pre><p><dl>
<dt>S<dd>Silhouette mask that has non-zero pixels where the motion occurs.
<dt>MHI<dd>Motion history image, that is updated by the function (single-channel, 32-bit floating-point)
<dt>timestamp<dd>Current time in milliseconds or other units.
<dt>duration<dd>Maximal duration of motion track in the same units as <em>timestamp</em>.
</dl></p><p>
The function <a href="#decl_cvUpdateMotionHistory">cvUpdateMotionHistory</a> updates the motion history image as following:</p>
<pre>
MHI(x,y)=timestamp  if S(x,y)!=0
         0          if S(x,y)=0 and MHI(x,y)&lt;timestamp-duration
         MHI(x,y)   otherwise
</pre><p>
That is, MHI pixels where motion occurs are set to the current timestamp, while the pixels
where motion happened far ago are cleared.
</p>


<hr><h3><a name="decl_cvCalcMotionGradient">CalcMotionGradient</a></h3>
<p class="Blurb">Calculates gradient orientation of motion history image</p>
<pre>
void cvCalcMotionGradient( const CvArr* MHI, CvArr* mask, CvArr* orientation,
                           double delta1, double delta2, int apertureSize=3 );
</pre><p><dl>
<dt>MHI<dd>Motion history image.
<dt>mask<dd>Mask image; marks pixels where motion gradient data is correct. Output
parameter.
<dt>orientation<dd>Motion gradient orientation image; contains angles from 0 to ~360&deg;.
<dt>delta1, delta2<dd>The function finds minimum (m(x,y)) and maximum (M(x,y)) MHI values over
each pixel (x,y) neihborhood and assumes the gradient is valid only if
<pre>min(delta1,delta2) &lt;= M(x,y)-m(x,y) &lt;= max(delta1,delta2).</pre>
<dt>apertureSize<dd>Aperture size of derivative operators used by the function:
CV_SCHARR, 1, 3, 5 or 7 (see <a href="OpenCVRef_ImageProcessing.htm#decl_cvSobel">cvSobel</a>).
</dl></p><p>
The function <a href="#decl_cvCalcMotionGradient">cvCalcMotionGradient</a> calculates the derivatives <em>Dx</em> and <em>Dy</em> of
<em>MHI</em> and then calculates gradient orientation as:</p>
<pre>
orientation(x,y)=arctan(Dy(x,y)/Dx(x,y))
</pre>
<p>
where both <em>Dx(x,y)</em>' and <em>Dy(x,y)</em>' signs are taken into account
(as in <a href="OpenCVRef_BasicFuncs.htm#decl_cvCartToPolar">cvCartToPolar</a> function). After that <em>mask</em> is filled to indicate
where the orientation is valid (see <em>delta1</em> and <em>delta2</em> description).
</p>


<hr><h3><a name="decl_cvCalcGlobalOrientation">CalcGlobalOrientation</a></h3>
<p class="Blurb">Calculates global motion orientation of some selected region</p>
<pre>
double cvCalcGlobalOrientation( const CvArr* orientation, const CvArr* mask, const CvArr* MHI,
                                double currTimestamp, double mhiDuration );
</pre><p><dl>
<dt>orientation<dd>Motion gradient orientation image; calculated by the function
<a href="#decl_cvCalcMotionGradient">cvCalcMotionGradient</a>.
<dt>mask<dd>Mask image. It may be a conjunction of valid gradient mask, obtained with
<a href="#decl_cvCalcMotionGradient">cvCalcMotionGradient</a> and mask of the region, whose direction needs to be
calculated.
<dt>MHI<dd>Motion history image.
<dt>timestamp<dd>Current time in milliseconds or other units, it is better to store time passed to
<a href="#decl_cvUpdateMotionHistory">cvUpdateMotionHistory</a> before and reuse it here, because running <a href="#decl_cvUpdateMotionHistory">cvUpdateMotionHistory</a>
and <a href="#decl_cvCalcMotionGradient">cvCalcMotionGradient</a> on large images may take some time.
<dt>duration<dd>Maximal duration of motion track in milliseconds, the same as in <a href="#decl_cvUpdateMotionHistory">cvUpdateMotionHistory</a>.
</dl></p><p>
The function <a href="#decl_cvCalcGlobalOrientation">cvCalcGlobalOrientation</a> calculates the general motion direction in
the selected region and returns the angle between 0&deg; and 360&deg;.
At first the function builds the orientation histogram and finds the basic
orientation as a coordinate of the histogram maximum. After that the function
calculates the shift relative to the basic orientation as a weighted sum of all
orientation vectors: the more recent is the motion, the greater is the weight.
The resultant angle is a circular sum of the basic orientation and the shift.


<hr><h3><a name="decl_cvSegmentMotion">SegmentMotion</a></h3>
<p class="Blurb">Segments whole motion into separate moving parts</p>
<pre>
CvSeq* cvSegmentMotion( const CvArr* MHI, CvArr* segMask, CvMemStorage* storage,
                        double timestamp, double segthresh );
</pre><p><dl>
<dt>mhi<dd>Motion history image.
<dt>segMask<dd>Image where the mask found should be stored, single-channel, 32-bit floating-point.
<dt>storage<dd>Memory storage that will contain a sequence of motion connected components.
<dt>timestamp<dd>Current time in milliseconds or other units.
<dt>segthresh<dd>Segmentation threshold; recommended to be equal to the interval
between motion history "steps" or greater.
</dl></p><p>
The function <a href="#decl_cvSegmentMotion">cvSegmentMotion</a> finds all the motion segments and marks them in <em>segMask</em>
with individual values each (1,2,...). It also returns a sequence of <a href="OpenCVRef_ImageProcessing.htm#decl_CvConnectedComp">CvConnectedComp</a> structures,
one per each motion components. After than the motion direction for every component can be calculated
with <a href="#decl_cvCalcGlobalOrientation">cvCalcGlobalOrientation</a> using extracted mask of the particular component
(using <a href="OpenCVRef_BasicFuncs.htm#decl_cvCmp">cvCmp</a>)
</p>


<hr><h2><a name="ch4_tracking">Object Tracking</a></h2>


<hr><h3><a name="decl_cvMeanShift">MeanShift</a></h3>
<p class="Blurb">Finds object center on back projection</p>
<pre>
int cvMeanShift( const CvArr* imgProb, CvRect windowIn,
                 CvTermCriteria criteria, CvConnectedComp* comp );
</pre><p><dl>
<dt>imgProb<dd>Back projection of object histogram (see <a href="OpenCVRef_ImageProcessing.htm#decl_cvCalcBackProject">cvCalcBackProject</a>).
<dt>windowIn<dd>Initial search window.
<dt>criteria<dd>Criteria applied to determine when the window search should be
finished.
<dt>comp<dd>Resultant structure that contains converged search window coordinates
(<em>comp->rect</em> field) and sum of all pixels inside the window (<em>comp->area</em> field).
</dl></p><p>
The function <a href="#decl_cvMeanShift">cvMeanShift</a> iterates to find the object center given its back projection and
initial position of search window. The iterations are made until the search window
center moves by less than the given value and/or until the function has done the
maximum number of iterations. The function returns the number of iterations
made.
</p>


<hr><h3><a name="decl_cvCamShift">CamShift</a></h3>
<p class="Blurb">Finds object center, size, and orientation</p>
<pre>
int cvCamShift( const CvArr* imgProb, CvRect windowIn, CvTermCriteria criteria,
                CvConnectedComp* comp, CvBox2D* box=0 );
</pre><p><dl>
<dt>imgProb<dd>Back projection of object histogram (see <a href="OpenCVRef_ImageProcessing.htm#decl_cvCalcBackProject">cvCalcBackProject</a>).
<dt>windowIn<dd>Initial search window.
<dt>criteria<dd>Criteria applied to determine when the window search should be
finished.
<dt>comp<dd>Resultant structure that contains converged search window coordinates
(<em>comp->rect</em> field) and sum of all pixels inside the window (<em>comp->area</em> field).
<dt>box<dd>Circumscribed box for the object. If not <em>NULL</em>, contains object size and
orientation.
</dl></p><p>
The function <a href="#decl_cvCamShift">cvCamShift</a> implements CAMSHIFT object tracking
algrorithm (<a href="#camshift_paper">[Bradski98]</a>).
First, it finds an object center using <a href="#decl_cvMeanShift">cvMeanShift</a> and,
after that, calculates the object size and orientation. The function returns
number of iterations made within <a href="#decl_cvMeanShift">cvMeanShift</a>.
</p><p>
<a href="#decl_CvCamShiftTracker">CvCamShiftTracker</a> class declared in cv.hpp implements color object tracker that uses
the function.
</p>
<p><a name="camshift_paper"></a><b>
[Bradski98] G.R. Bradski. Computer vision face tracking as a component of a perceptual
user interface. In Workshop on Applications of Computer Vision, pages 214–219,
Princeton, NJ, Oct. 1998.</b><br>
Updated version can be viewed online at
<a href="http://www.intel.com/technology/itj/q21998/articles/art_2.htm">
http://www.intel.com/technology/itj/q21998/articles/art_2.htm</a>.<br>
Also, it is included into OpenCV distribution (<a href="../papers/camshift.pdf">camshift.pdf</a>)</p>

<hr><h3><a name="decl_cvSnakeImage">SnakeImage</a></h3>
<p class="Blurb">Changes contour position to minimize its energy</p>
<pre>
void cvSnakeImage( const IplImage* image, CvPoint* points, int length,
                   float* alpha, float* beta, float* gamma, int coeffUsage,
                   CvSize win, CvTermCriteria criteria, int calcGradient=1 );
</pre><p><dl>
<dt>image<dd>The source image or external energy field.
<dt>points<dd>Contour points (snake).
<dt>length<dd>Number of points in the contour.
<dt>alpha<dd>Weight[s] of continuity energy, single float or array of <em>length</em> floats,
             one per each contour point.
<dt>beta<dd>Weight[s] of curvature energy, similar to <em>alpha</em>.
<dt>gamma<dd>Weight[s] of image energy, similar to <em>alpha</em>.
<dt>coeffUsage<dd>Variant of usage of the previous three parameters:
<ul>
<li><em>CV_VALUE</em> indicates that each of <em>alpha, beta, gamma</em> is a pointer to a single
  value to be used for all points;
<li><em>CV_ARRAY</em> indicates that each of <em>alpha, beta, gamma</em> is a pointer to an array
  of coefficients different for all the points of the snake. All the arrays must
  have the size equal to the contour size.
</ul>
<dt>win<dd>Size of neighborhood of every point used to search the minimum, both <em>win.width</em> and
<em>win.height</em> must be odd.
<dt>criteria<dd>Termination criteria.
<dt>calcGradient<dd>Gradient flag. If not 0, the function calculates gradient magnitude for every image pixel and
consideres it as the energy field, otherwise the input image itself is considered.
</dl></p><p>
The function <a href="#decl_cvSnakeImage">cvSnakeImage</a> updates snake in order to minimize its total energy that is a sum
of internal energy that depends on contour shape (the smoother contour is, the smaller internal energy is)
and external energy that depends on the energy field and reaches minimum at the local energy extremums
that correspond to the image edges in case of image gradient.</p><p>
The parameter <em>criteria.epsilon</em> is used to define the minimal number of points
that must be moved during any iteration to keep the iteration process running.
<p>
If at some iteration the number of moved points is less than <em>criteria.epsilon</em> or the function
performed <em>criteria.maxIter</em> iterations, the function terminates.
</p>


<hr><h2><a name="ch4_optflow">Optical Flow</a></h2>

<hr><h3><a name="decl_cvCalcOpticalFlowHS">CalcOpticalFlowHS</a></h3>
<p class="Blurb">Calculates optical flow for two images</p>
<pre>
void cvCalcOpticalFlowHS( const CvArr* imgA, const CvArr* imgB, int usePrevious,
                          CvArr* velx, CvArr* vely, double lambda,
                          CvTermCriteria criteria );
</pre><p><dl>
<dt>imgA<dd>First image, 8-bit, single-channel.
<dt>imgB<dd>Second image, 8-bit, single-channel.
<dt>usePrevious<dd>Uses previous (input) velocity field.
<dt>velx<dd>Horizontal component of the optical flow of the same size as input images,
            32-bit floating-point, single-channel.
<dt>vely<dd>Vertical component of the optical flow of the same size as input images,
            32-bit floating-point, single-channel.
<dt>lambda<dd>Lagrangian multiplier.
<dt>criteria<dd>Criteria of termination of velocity computing.
</dl></p><p>
The function <a href="#decl_cvCalcOpticalFlowHS">cvCalcOpticalFlowHS</a> computes flow for every pixel of the first input image using
Horn & Schunck algorithm <a href="#optflowhs_paper">[Horn81]</a>.
</p>
<p><a name="disttrans_paper"></a><b>
[Horn81] Berthold K.P. Horn and Brian G. Schunck. Determining Optical Flow.
Artificial Intelligence, 17, pp. 185-203, 1981.
</b></p>


<hr><h3><a name="decl_cvCalcOpticalFlowLK">CalcOpticalFlowLK</a></h3>
<p class="Blurb">Calculates optical flow for two images</p>
<pre>
void cvCalcOpticalFlowLK( const CvArr* imgA, const CvArr* imgB, CvSize winSize,
                          CvArr* velx, CvArr* vely );
</pre><p><dl>
<dt>imgA<dd>First image, 8-bit, single-channel.
<dt>imgB<dd>Second image, 8-bit, single-channel.
<dt>winSize<dd>Size of the averaging window used for grouping pixels.
<dt>velx<dd>Horizontal component of the optical flow of the same size as input images,
            32-bit floating-point, single-channel.
<dt>vely<dd>Vertical component of the optical flow of the same size as input images,
            32-bit floating-point, single-channel.
</dl></p><p>
The function <a href="#decl_cvCalcOpticalFlowLK">cvCalcOpticalFlowLK</a> computes flow for every pixel of the first input image using
Lucas & Kanade algorithm <a href="#optflowlk_paper">[Lucas81]</a>.
</p>
</p>
<p><a name="optflowlk_paper"></a><b>
[Lucas81] Lucas, B., and Kanade, T. An Iterative Image
Registration Technique with an Application to Stereo
Vision, Proc. of 7th International Joint Conference on
Artificial Intelligence (IJCAI), pp. 674-679.
</b></p>


<hr><h3><a name="decl_cvCalcOpticalFlowBM">CalcOpticalFlowBM</a></h3>
<p class="Blurb">Calculates optical flow for two images by block matching method</p>
<pre>
void cvCalcOpticalFlowBM( const CvArr* imgA, const CvArr* imgB, CvSize blockSize,
                          CvSize shiftSize, CvSize maxRange, int usePrevious,
                          CvArr* velx, CvArr* vely );
</pre><p><dl>
<dt>imgA<dd>First image, 8-bit, single-channel.
<dt>imgB<dd>Second image, 8-bit, single-channel.
<dt>blockSize<dd>Size of basic blocks that are compared.
<dt>shiftSize<dd>Block coordinate increments.
<dt>maxRange<dd>Size of the scanned neighborhood in pixels around block.
<dt>usePrevious<dd>Uses previous (input) velocity field.
<dt>velx<dd>Horizontal component of the optical flow of<br>
            floor((imgA->width - blockSize.width)/shiftSize.width) &times; floor((imgA->height - blockSize.height)/shiftSize.height) size,
            32-bit floating-point, single-channel.
<dt>vely<dd>Vertical component of the optical flow of the same size <em>velx</em>,
            32-bit floating-point, single-channel.
</dl></p><p>
The function <a href="#decl_cvCalcOpticalFlowBM">cvCalcOpticalFlowBM</a> calculates optical flow for
overlapped blocks <em>blockSize.width&times;blockSize.height</em> pixels each,
thus the velocity fields are smaller than the original images. For every block in <em>imgA</em>
the functions tries to find a similar block in <em>imgB</em> in some neighborhood of the original
block or shifted by (velx(x0,y0),vely(x0,y0)) block as has been calculated
by previous function call (if <em>usePrevious=1</em>)
</p>


<hr><h3><a name="decl_cvCalcOpticalFlowPyrLK">CalcOpticalFlowPyrLK</a></h3>
<p class="Blurb">Calculates optical flow for a sparse feature set using iterative Lucas-Kanade method in
        pyramids</p>
<pre>
void cvCalcOpticalFlowPyrLK( const CvArr* imgA, const CvArr* imgB, CvArr* pyrA, CvArr* pyrB,
                             CvPoint2D32f* featuresA, CvPoint2D32f* featuresB,
                             int count, CvSize winSize, int level, char* status,
                             float* error, CvTermCriteria criteria , int flags );
</pre><p><dl>
<dt>imgA<dd>First frame, at time <em>t</em>.
<dt>imgB<dd>Second frame, at time <em>t + dt</em> .
<dt>pyrA<dd>Buffer for the pyramid for the first frame. If the pointer is not <em>NULL</em> ,
the buffer must have a sufficient size to store the pyramid from level <em>1</em> to
level #<em>level</em> ; the total size of <em>( imgSize.width +8)* imgSize.height /3</em> bytes
is sufficient.
<dt>pyrB<dd>Similar to <em>pyrA</em> , applies to the second frame.
<dt>featuresA<dd>Array of points for which the flow needs to be found.
<dt>featuresB<dd>Array of 2D points containing calculated new positions of input
<dt>features<dd>in the second image.
<dt>count<dd>Number of feature points.
<dt>winSize<dd>Size of the search window of each pyramid level.
<dt>level<dd>Maximal pyramid level number. If <em>0</em> , pyramids are not used (single level),
if <em>1</em> , two levels are used, etc.
<dt>status<dd>Array. Every element of the array is set to <em>1</em> if the flow for the
corresponding feature has been found, <em>0</em> otherwise.
<dt>error<dd>Array of double numbers containing difference between patches around the
original and moved points. Optional parameter; can be <em>NULL </em>.
<dt>criteria<dd>Specifies when the iteration process of finding the flow for each point
on each pyramid level should be stopped.
<dt>flags<dd>Miscellaneous flags:
<ul>
<li>  <em>CV_LKFLOW_PYR_A_READY </em>, pyramid for the first frame is precalculated before
  the call;
<li>  <em>CV_LKFLOW_PYR_B_READY</em> , pyramid for the second frame is precalculated before
  the call;
<li>  <em>CV_LKFLOW_INITIAL_GUESSES</em> , array B contains initial coordinates of features
  before the function call.
</ul>
</dl></p><p>
The function <a href="#decl_cvCalcOpticalFlowPyrLK">cvCalcOpticalFlowPyrLK</a> implements
sparse iterative version of Lucas-Kanade optical flow in pyramids (<a href="#optflow_paper">[Bouguet00]</a>).
Calculates the optical flow between two images
for the given set of points. The function finds the flow with sub-pixel
accuracy.
<p>
Both parameters <em>pyrA</em> and <em>pyrB</em> comply with the following rules: if the image
pointer is 0 , the function allocates the buffer internally, calculates the
pyramid, and releases the buffer after processing. Otherwise, the function
calculates the pyramid and stores it in the buffer unless the flag
<em>CV_LKFLOW_PYR_A[B]_READY</em> is set. The image should be large enough to fit the
Gaussian pyramid data. After the function call both pyramids are calculated and
the ready flag for the corresponding image can be set in the next call.
</p>
<p><a name="camshift_paper"></a><b>
[Bouguet00] Jean-Yves Bouguet. Pyramidal Implementation of the Lucas Kanade Feature Tracker.</b><br>
The paper is included into OpenCV distribution (<a href="../papers/algo_tracking.pdf">algo_tracking.pdf</a>)</p>


<hr><h2><a name="ch4_estimators">Estimators</a></h2>

<hr><h3><a name="decl_CvKalman">CvKalman</a></h3>
<p class="Blurb">Kalman filter state</p>
<pre>
typedef struct CvKalman
{
    int MP;                     /* number of measurement vector dimensions */
    int DP;                     /* number of state vector dimensions */
    int CP;                     /* number of control vector dimensions */

    /* backward compatibility fields */
#if 1
    float* PosterState;         /* =state_pre->data.fl */
    float* PriorState;          /* =state_post->data.fl */
    float* DynamMatr;           /* =transition_matrix->data.fl */
    float* MeasurementMatr;     /* =measurement_matrix->data.fl */
    float* MNCovariance;        /* =measurement_noise_cov->data.fl */
    float* PNCovariance;        /* =process_noise_cov->data.fl */
    float* KalmGainMatr;        /* =gain->data.fl */
    float* PriorErrorCovariance;/* =error_cov_pre->data.fl */
    float* PosterErrorCovariance;/* =error_cov_post->data.fl */
    float* Temp1;               /* temp1->data.fl */
    float* Temp2;               /* temp2->data.fl */
#endif

    CvMat* state_pre;           /* predicted state (x'(k)):
                                    x(k)=A*x(k-1)+B*u(k) */
    CvMat* state_post;          /* corrected state (x(k)):
                                    x(k)=x'(k)+K(k)*(z(k)-H*x'(k)) */
    CvMat* transition_matrix;   /* state transition matrix (A) */
    CvMat* control_matrix;      /* control matrix (B)
                                   (it is not used if there is no control)*/
    CvMat* measurement_matrix;  /* measurement matrix (H) */
    CvMat* process_noise_cov;   /* process noise covariance matrix (Q) */
    CvMat* measurement_noise_cov; /* measurement noise covariance matrix (R) */
    CvMat* error_cov_pre;       /* priori error estimate covariance matrix (P'(k)):
                                    P'(k)=A*P(k-1)*At + Q)*/
    CvMat* gain;                /* Kalman gain matrix (K(k)):
                                    K(k)=P'(k)*Ht*inv(H*P'(k)*Ht+R)*/
    CvMat* error_cov_post;      /* posteriori error estimate covariance matrix (P(k)):
                                    P(k)=(I-K(k)*H)*P'(k) */
    CvMat* temp1;               /* temporary matrices */
    CvMat* temp2;
    CvMat* temp3;
    CvMat* temp4;
    CvMat* temp5;
}
CvKalman;
</pre>
<p>
The structure <a href="#decl_CvKalman">CvKalman</a> is used to keep Kalman filter state. It is created
by <a href="#decl_cvCreateKalman">cvCreateKalman</a> function, updated by <a href="#decl_cvKalmanPredict">cvKalmanPredict</a> and
<a href="#decl_cvKalmanCorrect">cvKalmanCorrect</a> functions and released by <a href="#decl_cvReleaseKalman">cvReleaseKalman</a> functions.
Normally, the structure is used for standard Kalman filter (notation and formulae are borrowed
from excellent Kalman tutorial <a href="#kalman_paper">[Welch95]</a>):</p>
<pre>
x<sub>k</sub>=A&bull;x<sub>k-1</sub>+B&bull;u<sub>k</sub>+w<sub>k</sub>
z<sub>k</sub>=H&bull;x<sub>k</sub>+v<sub>k</sub>,
</pre>
<p>where:</p>
<pre>
x<sub>k</sub> (x<sub>k-1</sub>) - state of the system at the moment k (k-1)
z<sub>k</sub> - measurement of the system state at the moment k
u<sub>k</sub> - external control applied at the moment k

w<sub>k</sub> and v<sub>k</sub> are normally-distributed process and measurement noise, respectively:
p(w) ~ N(0,Q)
p(v) ~ N(0,R),

that is,
Q - process noise covariance matrix, constant or variable,
R - measurement noise covariance matrix, constant or variable
</pre><p>
In case of standard Kalman filter, all the matrices: A, B, H, Q and R are initialized once after
<a href="#decl_CvKalman">CvKalman</a> structure is allocated via <a href="#decl_cvCreateKalman">cvCreateKalman</a>.
However, the same structure and the same functions may be used to simulate extended Kalman filter by
linearizing extended Kalman filter equation in the current system state neighborhood,
in this case A, B, H (and, probably, Q and R) should be updated on every step.
</p>
<p><a name="disttrans_paper"></a><b>
[Welch95] Greg Welch, Gary Bishop. An Introduction To the Kalman Filter.
Technical Report TR95-041, University of North Carolina at Chapel Hill, 1995.
</b>
Online version is available at <a href="http://www.cs.unc.edu/~welch/kalman/kalman_filter/kalman.html">
http://www.cs.unc.edu/~welch/kalman/kalman_filter/kalman.html</a>
</p>


<hr><h3><a name="decl_cvCreateKalman">CreateKalman</a></h3>
<p class="Blurb">Allocates Kalman filter structure</p>
<pre>
CvKalman* cvCreateKalman( int dynamParams, int measureParams, int controParams=0 );
</pre><p><dl>
<dt>dynamParams<dd>dimensionality of the state vector
<dt>measureParams<dd>dimensionality of the measurement vector
<dt>controlParams<dd>dimensionality of the control vector
</dl></p><p>
The function <a href="#decl_cvCreateKalman">cvCreateKalman</a> allocates <a href="#decl_CvKalman">CvKalman</a> and all its matrices
and initializes them somehow.
</p>


<hr><h3><a name="decl_cvReleaseKalman">ReleaseKalman</a></h3>
<p class="Blurb">Deallocates Kalman filter structure</p>
<pre>
void cvReleaseKalman(CvKalman** kalman );
</pre><p><dl>
<dt>kalman<dd>double pointer to the Kalman filter structure.
</dl></p><p>
The function <a href="#decl_cvReleaseKalman">cvReleaseKalman</a> releases the structure <a href="#decl_CvKalman">CvKalman</a>
and all underlying matrices.
</p>


<hr><h3><a name="decl_cvKalmanPredict">KalmanPredict</a></h3>
<p class="Blurb">Estimates subsequent model state</p>
<pre>
const CvMat* cvKalmanPredict( CvKalman* kalman, const CvMat* control=NULL );
#define cvKalmanUpdateByTime cvKalmanPredict
</pre><p><dl>
<dt>kalman<dd>Kalman filter state.
<dt>control<dd>Control vector (u<sub>k</sub>),
               should be NULL iff there is no external control (<em>controlParams</em>=0).
</dl></p><p>
The function <a href="#decl_cvKalmanPredict">cvKalmanPredict</a> estimates the subsequent stochastic model state
by its current state and stores it at <em>kalman->state_pre</em>:</p>
<pre>
    x'<sub>k</sub>=A&bull;x<sub>k</sub>+B&bull;u<sub>k</sub>
    P'<sub>k</sub>=A&bull;P<sub>k-1</sub>*A<sup>T</sup> + Q,
where
x'<sub>k</sub> is predicted state (kalman->state_pre),
x<sub>k-1</sub> is corrected state on the previous step (kalman->state_post)
                (should be initialized somehow in the beginning, zero vector by default),
u<sub>k</sub> is external control (<em>control</em> parameter),
P'<sub>k</sub> is priori error covariance matrix (kalman->error_cov_pre)
P<sub>k-1</sub> is posteriori error covariance matrix on the previous step (kalman->error_cov_post)
                (should be initialized somehow in the beginning, identity matrix by default),
</pre>
The function returns the estimated state.
</p>


<hr><h3><a name="decl_cvKalmanCorrect">KalmanCorrect</a></h3>
<p class="Blurb">Adjusts model state</p>
<pre>
void cvKalmanCorrect( CvKalman* kalman, const CvMat* measurement=NULL );
#define cvKalmanUpdateByMeasurement cvKalmanCorrect
</pre><p><dl>
<dt>kalman<dd>Pointer to the structure to be updated.
<dt>measurement<dd>Pointer to the structure CvMat containing the measurement vector.
</dl></p><p>
The function <a href="#decl_cvKalmanCorrect">cvKalmanCorrect</a> adjusts stochastic model state on the
basis of the given measurement of the model state:</p>
<pre>
K<sub>k</sub>=P'<sub>k</sub>&bull;H<sup>T</sup>&bull;(H&bull;P'<sub>k</sub>&bull;H<sup>T</sup>+R)<sup>-1</sup>
x<sub>k</sub>=x'<sub>k</sub>+K<sub>k</sub>&bull;(z<sub>k</sub>-H&bull;x'<sub>k</sub>)
P<sub>k</sub>=(I-K<sub>k</sub>&bull;H)&bull;P'<sub>k</sub>
where
z<sub>k</sub> - given measurement (<em>mesurement</em> parameter)
K<sub>k</sub> - Kalman "gain" matrix.
</pre>
<p>
The function stores adjusted state at <em>kalman->state_post</em> and returns it on output.
</p>

<h4>Example. Using Kalman filter to track a rotating point</h4>
<pre>
#include "cv.h"
#include "highgui.h"
#include &lt;math.h&gt;

int main(int argc, char** argv)
{
    /* A matrix data */
    const float A[] = { 1, 1, 0, 1 };

    IplImage* img = cvCreateImage( cvSize(500,500), 8, 3 );
    CvKalman* kalman = cvCreateKalman( 2, 1, 0 );
    /* state is (phi, delta_phi) - angle and angle increment */
    CvMat* state = cvCreateMat( 2, 1, CV_32FC1 );
    CvMat* process_noise = cvCreateMat( 2, 1, CV_32FC1 );
    /* only phi (angle) is measured */
    CvMat* measurement = cvCreateMat( 1, 1, CV_32FC1 );
    CvRandState rng;
    int code = -1;

    cvRandInit( &rng, 0, 1, -1, CV_RAND_UNI );

    cvZero( measurement );
    cvNamedWindow( "Kalman", 1 );

    for(;;)
    {
        cvRandSetRange( &rng, 0, 0.1, 0 );
        rng.disttype = CV_RAND_NORMAL;

        cvRand( &rng, state );

        memcpy( kalman->transition_matrix->data.fl, A, sizeof(A));
        cvSetIdentity( kalman->measurement_matrix, cvRealScalar(1) );
        cvSetIdentity( kalman->process_noise_cov, cvRealScalar(1e-5) );
        cvSetIdentity( kalman->measurement_noise_cov, cvRealScalar(1e-1) );
        cvSetIdentity( kalman->error_cov_post, cvRealScalar(1));
        /* choose random initial state */
        cvRand( &rng, kalman->state_post );

        rng.disttype = CV_RAND_NORMAL;

        for(;;)
        {
            #define calc_point(angle)                                      \
                cvPoint( cvRound(img->width/2 + img->width/3*cos(angle)),  \
                         cvRound(img->height/2 - img->width/3*sin(angle)))

            float state_angle = state->data.fl[0];
            CvPoint state_pt = calc_point(state_angle);

            /* predict point position */
            const CvMat* prediction = cvKalmanPredict( kalman, 0 );
            float predict_angle = prediction->data.fl[0];
            CvPoint predict_pt = calc_point(predict_angle);
            float measurement_angle;
            CvPoint measurement_pt;

            cvRandSetRange( &rng, 0, sqrt(kalman->measurement_noise_cov->data.fl[0]), 0 );
            cvRand( &rng, measurement );

            /* generate measurement */
            cvMatMulAdd( kalman->measurement_matrix, state, measurement, measurement );

            measurement_angle = measurement->data.fl[0];
            measurement_pt = calc_point(measurement_angle);

            /* plot points */
            #define draw_cross( center, color, d )                                 \
                cvLine( img, cvPoint( center.x - d, center.y - d ),                \
                             cvPoint( center.x + d, center.y + d ), color, 1, 0 ); \
                cvLine( img, cvPoint( center.x + d, center.y - d ),                \
                             cvPoint( center.x - d, center.y + d ), color, 1, 0 )

            cvZero( img );
            draw_cross( state_pt, CV_RGB(255,255,255), 3 );
            draw_cross( measurement_pt, CV_RGB(255,0,0), 3 );
            draw_cross( predict_pt, CV_RGB(0,255,0), 3 );
            cvLine( img, state_pt, predict_pt, CV_RGB(255,255,0), 3, 0 );

            /* adjust Kalman filter state */
            cvKalmanCorrect( kalman, measurement );

            cvRandSetRange( &rng, 0, sqrt(kalman->process_noise_cov->data.fl[0]), 0 );
            cvRand( &rng, process_noise );
            cvMatMulAdd( kalman->transition_matrix, state, process_noise, state );

            cvShowImage( "Kalman", img );
            code = cvWaitKey( 100 );

            if( code > 0 ) /* break current simulation by pressing a key */
                break;
        }
        if( code == 27 ) /* exit by ESCAPE */
            break;
    }

    return 0;
}
</pre>



<hr><h3><a name="data_CvConDensation">CvConDensation</a></h3>
<p class="Blurb">ConDenstation state</p>
<pre>
    typedef struct CvConDensation
    {
        int MP;     //Dimension of measurement vector
        int DP;     // Dimension of state vector
        float* DynamMatr;       // Matrix of the linear Dynamics system
        float* State;           // Vector of State
        int SamplesNum;         // Number of the Samples
        float** flSamples;      // array of the Sample Vectors
        float** flNewSamples;   // temporary array of the Sample Vectors
        float* flConfidence;    // Confidence for each Sample
        float* flCumulative;    // Cumulative confidence
        float* Temp;            // Temporary vector
        float* RandomSample;    // RandomVector to update sample set
        CvRandState* RandS;     // Array of structures to generate random vectors
    } CvConDensation;
</pre>
<p>
The structure <a href="#decl_CvConDensation">CvConDensation</a> stores CONditional DENSity propagATION tracker state.
The information about the algorithm can be found at
<a href="http://www.dai.ed.ac.uk/CVonline/LOCAL_COPIES/ISARD1/condensation.html">
http://www.dai.ed.ac.uk/CVonline/LOCAL_COPIES/ISARD1/condensation.html</a>
</p>


<hr><h3><a name="decl_cvCreateConDensation">CreateConDensation</a></h3>
<p class="Blurb">Allocates ConDensation filter structure</p>
<pre>
CvConDensation* cvCreateConDensation( int DynamParams, int MeasureParams, int SamplesNum );
</pre><p><dl>
<dt>DynamParams<dd>Dimension of the state vector.
<dt>MeasureParams<dd>Dimension of the measurement vector.
<dt>SamplesNum<dd>Number of samples.
</dl></p><p>
The function <a href="#decl_cvCreateConDensation">cvCreateConDensation</a> creates <a href="#decl_CvConDensation">CvConDensation</a>
structure and returns pointer to the structure.
</p>


<hr><h3><a name="decl_cvReleaseConDensation">ReleaseConDensation</a></h3>
<p class="Blurb">Deallocates ConDensation filter structure</p>
<pre>
void cvReleaseConDensation( CvConDensation** ConDens );
</pre><p><dl>
<dt>ConDens<dd>Pointer to the pointer to the structure to be released.
</dl></p><p>
The function <a href="#decl_cvReleaseConDensation">cvReleaseConDensation</a> releases the structure <a href="#decl_CvConDensation">CvConDensation</a> (see
<a href="#decl_CvConDensation">cvConDensation</a>) and frees all memory previously allocated for the structure.
</p>


<hr><h3><a name="decl_cvConDensInitSampleSet">ConDensInitSampleSet</a></h3>
<p class="Blurb">Initializes sample set for condensation algorithm</p>
<pre>
void cvConDensInitSampleSet( CvConDensation* ConDens, CvMat* lowerBound, CvMat* upperBound );
</pre><p><dl>
<dt>ConDens<dd>Pointer to a structure to be initialized.
<dt>lowerBound<dd>Vector of the lower boundary for each dimension.
<dt>upperBound<dd>Vector of the upper boundary for each dimension.
</dl></p><p>
The function <a href="#decl_cvConDensInitSampleSet">cvConDensInitSampleSet</a> fills the samples arrays in the structure
<a href="#decl_CvConDensation">CvConDensation</a> with values within specified ranges.
</p>


<hr><h3><a name="decl_cvConDensUpdateByTime">ConDensUpdateByTime</a></h3>
<p class="Blurb">Estimates subsequent model state</p>
<pre>
void cvConDensUpdateByTime( CvConDensation* ConDens );
</pre><p><dl>
<dt>ConDens<dd>Pointer to the structure to be updated.
</dl></p><p>
The function <a href="#decl_cvConDensUpdateByTime">cvConDensUpdateByTime</a> estimates the subsequent stochastic model state
from its current state.
</p>

</body>
</html>



